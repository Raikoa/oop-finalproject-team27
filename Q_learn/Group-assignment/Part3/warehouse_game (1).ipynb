{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf917ef9-a9b1-4e7b-b0fc-fba6fcca7030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box,MultiDiscrete\n",
    "import numpy as np\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c31e3-2cd6-47d3-adde-1155f5bd4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ec0c1-92bf-4672-8102-7692ba31fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d10888-1a45-46f3-9a85-29c357582e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, start_pos):\n",
    "        self._pos = np.array(start_pos, dtype=np.int32)\n",
    "        self._prev_state = None\n",
    "        self._prev_prev_state = None\n",
    "        self._carrying = None\n",
    "        self._prev_goal_dists = []    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcceacb-23c7-47dd-8b34-af9091c649d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Package:\n",
    "    def __init__(self, pos):\n",
    "        self._pos = pos\n",
    "        self._delivered = False\n",
    "        self._picked = False\n",
    "        self._assigned = None\n",
    "   \n",
    "    def copy(self):\n",
    "        return {\n",
    "            \"pos\": self._pos,\n",
    "            \"picked\": self._picked,\n",
    "            \"assigned_to\": self._assigned,\n",
    "            \"delivered\": self._delivered\n",
    "        }\n",
    "    def get_priority(self):\n",
    "        return 0\n",
    "    def on_pickup(self, pickup_reward):\n",
    "        return pickup_reward\n",
    "    def on_deliver(self, deliver_reward):\n",
    "        return deliver_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f62f9-ade9-47fd-8e7e-89103f65447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressPackage(Package):\n",
    "    def get_priority(self):\n",
    "        return 1\n",
    "    def on_pickup(self, pickup_reward):\n",
    "        return pickup_reward * 1.5\n",
    "    def on_deliver(self, deliver_reward):\n",
    "        return deliver_reward * 1.3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02b37c-c9ea-43c3-b83e-e8ab0dfa41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeavyPackage(Package):\n",
    "    def get_priority(self):\n",
    "        return -1\n",
    "    def on_pickup(self, pickup_reward):\n",
    "        return pickup_reward * 1.2\n",
    "    def on_deliver(self, deliver_reward):\n",
    "        return deliver_reward * 1.5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93319198-8d02-421a-b2a3-9607489053df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_map():\n",
    "    tok_map = [\n",
    "        ['#'] * 28,\n",
    "        ['#'] + ['.'] * 26 + ['#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#'] + ['.'] * 23 + ['.']  + ['.', '.', '#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#'] + ['.'] * 25 + ['O', '#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#'] + ['.'] * 23 + ['.']  + ['.', '.', '#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#', '.', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '@', '@', '@', '@', '.', '.', '.', '.', '.', '#'],\n",
    "        ['#'] + ['.'] * 26 + ['#'],\n",
    "        ['#'] * 28,\n",
    "    ]\n",
    "\n",
    "    return tok_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8959f7-5ffb-43ae-8bae-f3f673ed55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def manhattan(a, b):\n",
    "    \"\"\"Return Manhattan (L1) distance between two 2-tuples/iterables (x,y).\"\"\"\n",
    "    ax, ay = a\n",
    "    bx, by = b\n",
    "    return abs(ax - bx) + abs(ay - by)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9a1af-6ed7-4ffc-b478-c7ff74b2fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class with two agent\n",
    "\n",
    "\n",
    "\n",
    "class WareHouseEnv(Env):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_pos=(4, 24),\n",
    "        move_length=200,\n",
    "        step_cost=-0.01,\n",
    "        collision_penalty=-1.0,\n",
    "        pickup_reward=+20.0,\n",
    "        deliver_reward=+30.0,\n",
    "        completed_reward=+60.0,\n",
    "        max_num_packages=4,\n",
    "        agent_num=2,\n",
    "        num_of_express_pkg = 1,\n",
    "        num_of_heavy_pkg=1,\n",
    "    ):\n",
    "        #Public:\n",
    "        # ACTION SPACE\n",
    "        self.action_space = MultiDiscrete([4] * agent_num)\n",
    "        # OBS SPACE\n",
    "        low_one = np.array([\n",
    "            0, 0,     # ax, ay\n",
    "            0, 0,     # gx, gy\n",
    "            0,        # carrying_flag\n",
    "            0, 0, 0, 0,  # blocked flags\n",
    "            -14, -27\n",
    "        ], dtype=np.float32)\n",
    "        high_one = np.array([\n",
    "            14, 27,\n",
    "            14, 27,\n",
    "            1,\n",
    "            1, 1, 1, 1,\n",
    "            14, 27\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        low = np.tile(low_one, agent_num)\n",
    "        high = np.tile(high_one, agent_num)\n",
    "        self.observation_space = Box(low=low, high=high, dtype=np.float32)\n",
    "\n",
    "        #Private\n",
    "        self._agent_num = agent_num\n",
    "        self._start_pos = np.array(start_pos, dtype=np.int32)\n",
    "        self._agents = [Agent(self._start_pos.copy()  + np.random.randint(-1, 2, size=2)) for _ in range(agent_num)]\n",
    "\n",
    "        # MAP\n",
    "        self._map = init_map()\n",
    "        self._obstacles = {\"#\", \"@\", \"O\", \"%\"}\n",
    "\n",
    "        # Rewards\n",
    "        self._step_cost = step_cost\n",
    "        self._collision_penalty = collision_penalty\n",
    "        self._pickup_reward = pickup_reward\n",
    "        self._deliver_reward = deliver_reward\n",
    "        self._completed_reward = completed_reward\n",
    "\n",
    "        # Agent / env state\n",
    "        self._max_move_length = move_length\n",
    "        self._move_length = move_length\n",
    "        self._packages = []\n",
    "        self._max_num_packages = max_num_packages\n",
    "        self._num_of_express_pkg = num_of_express_pkg\n",
    "        self._num_of_heavy_pkg = num_of_heavy_pkg\n",
    "        # Locations\n",
    "        self._offload_positions = self._find_tiles(\"O\")\n",
    "        self._shelf_pos = self._find_tiles(\"@\")\n",
    "        self._drop_zone = self._offload_positions[0]\n",
    "     \n",
    "        # RNG\n",
    "        self._np_random = np.random.RandomState()\n",
    "\n",
    "        # spawn initial packages\n",
    "        for _ in range(max_num_packages - num_of_express_pkg - num_of_heavy_pkg):\n",
    "            self._spawn_goals()\n",
    "        for _ in range(num_of_express_pkg):\n",
    "            self._spawn_goals(\"express\")\n",
    "        for _ in range(num_of_heavy_pkg):\n",
    "            self._spawn_goals(\"heavy\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def init_pygame(self):\n",
    "        pygame.init()\n",
    "        self._tile_size = 24\n",
    "        self._colors = {\n",
    "            \"empty\": (240, 240, 240),\n",
    "            \"wall\": (80, 80, 80),\n",
    "            \"shelf\": (139, 69, 19),\n",
    "            \"offload\": (0, 120, 255),\n",
    "            \"normal_package\": (255, 165, 0),\n",
    "            \"express_package\": (255,0,0),\n",
    "            \"heavy_package\": (128,128,128),\n",
    "            \"agent\": (0, 200, 0),\n",
    "        }\n",
    "        self._screen = pygame.display.set_mode(\n",
    "            (self._tile_size * 28, self._tile_size * 15)\n",
    "        )\n",
    "        pygame.display.set_caption(\"Warehouse Environment\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def _find_tiles(self, tile_char):\n",
    "        out = []\n",
    "        for i, row in enumerate(self._map):\n",
    "            for j, c in enumerate(row):\n",
    "                if c == tile_char:\n",
    "                    out.append((i, j))\n",
    "        return out\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def _assign_packages(self):\n",
    "        \"\"\"\n",
    "        Assign each free agent exactly one package.\n",
    "        Deterministic tie-breaking:\n",
    "          - higher priority first\n",
    "          - if tie, closer distance first\n",
    "          - stable agent ordering\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "        free_agents = []\n",
    "        for i, agent in enumerate(self._agents):\n",
    "            if agent._carrying is None:\n",
    "                has_assigned = any(\n",
    "                    (p._assigned == i and not p._picked and not p._delivered)\n",
    "                    for p in self._packages\n",
    "                )\n",
    "                if not has_assigned:\n",
    "                    free_agents.append(i)\n",
    "\n",
    "        if not free_agents:\n",
    "            return\n",
    "\n",
    "        free_agents.sort()    \n",
    "\n",
    "       \n",
    "        unassigned_pkgs = []\n",
    "        for idx, p in enumerate(self._packages):\n",
    "            if (not p._picked) and (not p._delivered) and (p._assigned is None):\n",
    "                unassigned_pkgs.append(idx)\n",
    "\n",
    "        if not unassigned_pkgs:\n",
    "            return\n",
    "\n",
    "        # For each agent in deterministic order, assign best package\n",
    "        for a_idx in free_agents:\n",
    "            ax, ay = self._agents[a_idx]._pos\n",
    "\n",
    "            best = None  # (priority, -dist, p_idx)\n",
    "            for p_idx in unassigned_pkgs:\n",
    "                pkg = self._packages[p_idx]\n",
    "                px, py = pkg._pos\n",
    "                dist = abs(px - ax) + abs(py - ay)\n",
    "                cand = (pkg.get_priority(), -dist, p_idx)\n",
    "\n",
    "                if best is None or cand > best:\n",
    "                    best = cand\n",
    "\n",
    "            if best is None:\n",
    "                continue\n",
    "\n",
    "            _, _, best_idx = best\n",
    "            self._packages[best_idx]._assigned = a_idx\n",
    "\n",
    "            unassigned_pkgs.remove(best_idx)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def _get_current_goal(self, i):\n",
    "        agent = self._agents[i]\n",
    "\n",
    "        if agent._carrying is not None:\n",
    "            return self._drop_zone\n",
    "        \n",
    "        for pkg in self._packages:\n",
    "            if pkg._assigned == i:\n",
    "                return pkg._pos\n",
    "\n",
    "        return None\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def _shape_reward(self, prev_state, reward, agent_index):\n",
    "        goal = self._get_current_goal(agent_index)\n",
    "        if goal is None:\n",
    "            return reward\n",
    "\n",
    "        gx, gy = goal\n",
    "        ax, ay = self._agents[agent_index]._pos\n",
    "        px, py = prev_state\n",
    "\n",
    "        old_dist = abs(px - gx) + abs(py - gy)\n",
    "        new_dist = abs(ax - gx) + abs(ay - gy)\n",
    "\n",
    "        return reward + 0.01 * (old_dist - new_dist)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def _spawn_goals(self, type=None):\n",
    "        if len(self._packages) < self._max_num_packages:\n",
    "\n",
    "            existing = {tuple(p._pos) for p in self._packages if not getattr(p, \"_picked\", False)}\n",
    "\n",
    "            free_shelves = [\n",
    "                s for s in self._shelf_pos\n",
    "                if tuple(s) not in existing\n",
    "            ]\n",
    "\n",
    "            if len(free_shelves) == 0:\n",
    "                return\n",
    "\n",
    "            pos = free_shelves[self._np_random.randint(len(free_shelves))]\n",
    "\n",
    "            if type == \"express\":\n",
    "                new_pkg = ExpressPackage(pos)\n",
    "            elif type == \"heavy\":\n",
    "                new_pkg = HeavyPackage(pos)\n",
    "            else:\n",
    "                new_pkg = Package(pos)\n",
    "   \n",
    "          \n",
    "\n",
    "            self._packages.append(new_pkg)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def reset(self, seed=None, options=None):\n",
    "        for i in range(self._agent_num):\n",
    "            agent = self._agents[i]\n",
    "                \n",
    "            if seed is None:\n",
    "                agent._pos = self._start_pos + np.random.randint(-1, 2, size=2)\n",
    "            else:\n",
    "                agent._pos = self._start_pos.copy()\n",
    "\n",
    "            agent._carrying = None\n",
    "            agent._prev_state = agent._pos.copy()\n",
    "            agent._prev_prev_state = None\n",
    "            agent._prev_goal_dists = []\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            self._np_random.seed(seed)\n",
    "        \n",
    "\n",
    "        self._move_length = self._max_move_length\n",
    "        self._packages = []\n",
    "        for _ in range(self._max_num_packages - self._num_of_express_pkg - self._num_of_heavy_pkg):\n",
    "            self._spawn_goals()\n",
    "        for _ in range(self._num_of_express_pkg):\n",
    "            self._spawn_goals(\"express\")\n",
    "        for _ in range(self._num_of_heavy_pkg):\n",
    "            self._spawn_goals(\"heavy\")\n",
    "\n",
    "        return self._obs(), {\"packages\": [p.copy() for p in self._packages]}\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def _obs(self):\n",
    "        obs_list = []\n",
    "\n",
    "        for i in range(self._agent_num):\n",
    "            agent = self._agents[i]\n",
    "            ax, ay = agent._pos\n",
    "\n",
    "            goal = self._get_current_goal(i)\n",
    "            if goal is None:\n",
    "                gx, gy = ax, ay\n",
    "            else:\n",
    "                gx, gy = goal\n",
    "\n",
    "            carrying_flag = 1 if agent._carrying is not None else 0\n",
    "\n",
    "            blocked_up = 1 if (ax - 1 < 0 or self._map[ax - 1][ay] in self._obstacles) else 0\n",
    "            blocked_down = 1 if (ax + 1 >= 15 or self._map[ax + 1][ay] in self._obstacles) else 0\n",
    "            blocked_left = 1 if (ay - 1 < 0 or self._map[ax][ay - 1] in self._obstacles) else 0\n",
    "            blocked_right = 1 if (ay + 1 >= 28 or self._map[ax][ay + 1] in self._obstacles) else 0\n",
    "\n",
    "            other_rel = []\n",
    "            for j, other in enumerate(self._agents):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                ox, oy = other._pos\n",
    "                other_rel.extend([ox - ax, oy - ay])\n",
    "\n",
    "            obs_list.extend([\n",
    "                ax, ay,\n",
    "                gx, gy,\n",
    "                carrying_flag,\n",
    "                blocked_up, blocked_down, blocked_left, blocked_right,\n",
    "                *other_rel\n",
    "            ])\n",
    "\n",
    "        return np.array(obs_list, dtype=np.float32)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def step(self, actions):\n",
    "        rewards = [0.0 for _ in range(self._agent_num)]\n",
    "    \n",
    "        # always update package assignments\n",
    "        self._assign_packages()\n",
    "    \n",
    "        # Update agent history once (prev_prev <- prev <- current)\n",
    "        for agent in self._agents:\n",
    "            agent._prev_prev_state = None if agent._prev_state is None else agent._prev_state.copy()\n",
    "            agent._prev_state = agent._pos.copy()\n",
    "        \n",
    "        \n",
    "    \n",
    "        # -------------------------\n",
    "        # PHASE 1: propose movement\n",
    "        # -------------------------\n",
    "        proposed_positions = []\n",
    "        blocked_flags = [False] * self._agent_num\n",
    "    \n",
    "        for i in range(self._agent_num):\n",
    "            agent = self._agents[i]\n",
    "            ax, ay = agent._pos\n",
    "    \n",
    "            a = actions[i]\n",
    "    \n",
    "      \n",
    "            if a == 0:\n",
    "                nx, ny = ax - 1, ay\n",
    "            elif a == 1:\n",
    "                nx, ny = ax + 1, ay\n",
    "            elif a == 2:\n",
    "                nx, ny = ax, ay + 1\n",
    "            elif a == 3:\n",
    "                nx, ny = ax, ay - 1\n",
    "            else:\n",
    "                nx, ny = ax, ay\n",
    "    \n",
    "            blocked = False\n",
    "    \n",
    "            if not (0 <= nx < 15 and 0 <= ny < 28) or self._map[nx][ny] in self._obstacles:\n",
    "                rewards[i] += self._collision_penalty\n",
    "                nx, ny = ax, ay\n",
    "                blocked = True\n",
    "    \n",
    "            other_positions = [tuple(a._pos) for j, a in enumerate(self._agents) if j != i]\n",
    "            if (nx, ny) in other_positions:\n",
    "                rewards[i] += self._collision_penalty * 2.0\n",
    "                nx, ny = ax, ay\n",
    "                blocked = True\n",
    "    \n",
    "            rewards[i] += self._step_cost\n",
    "    \n",
    "            proposed_positions.append((nx, ny))\n",
    "            blocked_flags[i] = blocked\n",
    "    \n",
    "    \n",
    "        swap_block = [False] * self._agent_num\n",
    "        for i in range(self._agent_num):\n",
    "            for j in range(i + 1, self._agent_num):\n",
    "                if (tuple(self._agents[i]._pos) == proposed_positions[j] and\n",
    "                    tuple(self._agents[j]._pos) == proposed_positions[i]):\n",
    "                    swap_block[i] = True\n",
    "                    swap_block[j] = True\n",
    "    \n",
    "        for i in range(self.agent_num):\n",
    "            if swap_block[i]:\n",
    "                # penalty for collision with other agents impact learning\n",
    "                # rewards[i] += self.collision_penalty * 2.0\n",
    "                \n",
    "                proposed_positions[i] = tuple(self._agents[i]._pos)\n",
    "                blocked_flags[i] = True\n",
    "    \n",
    "        # -------------------------\n",
    "        # PHASE 2: update positions\n",
    "        # -------------------------\n",
    "        for i in range(self._agent_num):\n",
    "            \n",
    "            self._agents[i]._pos = np.array(proposed_positions[i])\n",
    "    \n",
    "        # -------------------------\n",
    "        # PHASE 3: package pickup\n",
    "        # -------------------------\n",
    "        for i in range(self._agent_num):\n",
    "            agent = self._agents[i]\n",
    "            if agent._carrying is not None:\n",
    "                continue\n",
    "    \n",
    "            ax, ay = agent._pos\n",
    "            closest_idx = None\n",
    "            closest_dist = float(\"inf\")\n",
    "    \n",
    "            for idx, pkg in enumerate(self._packages):\n",
    "      \n",
    "                if pkg._picked or pkg._delivered:\n",
    "                    continue\n",
    "    \n",
    "                px, py = pkg._pos\n",
    "                d = abs(px - ax) + abs(py - ay)\n",
    "    \n",
    "                if d <= 1 and d < closest_dist:\n",
    "                    closest_dist = d\n",
    "                    closest_idx = idx\n",
    "    \n",
    "            if closest_idx is not None:\n",
    "                pkg = self._packages[closest_idx]\n",
    "                pkg._picked = True\n",
    "                pkg._assigned = None\n",
    "                agent._carrying = pkg\n",
    "                rewards[i] += pkg.on_pickup(self, self._pickup_reward)\n",
    "\n",
    "    \n",
    "        # -------------------------\n",
    "        # PHASE 4: delivery\n",
    "        # -------------------------\n",
    "        for i in range(self._agent_num):\n",
    "            agent = self._agents[i]\n",
    "            if agent._carrying is None:\n",
    "                continue\n",
    "    \n",
    "            ox, oy = self._offload_positions[0]\n",
    "            if abs(agent._pos[0] - ox) + abs(agent._pos[1] - oy) <= 1:\n",
    "                try:\n",
    "                    agent._carrying._delivered = True\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "                agent._carrying = None\n",
    "                rewards[i] += pkg.on_deliver(self, self._deliver_reward)\n",
    "    \n",
    "        # -------------------------\n",
    "        # PHASE 5: shaping\n",
    "        # -------------------------\n",
    "        for i in range(self._agent_num):\n",
    "            agent = self._agents[i]\n",
    "    \n",
    "            rewards[i] = self._shape_reward(agent._prev_state.copy(), rewards[i], i)\n",
    "    \n",
    "            if agent._prev_prev_state is not None:\n",
    "                reversed_move = (\n",
    "                    agent._pos[0] == agent._prev_prev_state[0] and\n",
    "                    agent._pos[1] == agent._prev_prev_state[1]\n",
    "                )\n",
    "                if reversed_move:\n",
    "                    goal = self._get_current_goal(i)\n",
    "                    if goal is not None:\n",
    "                        gx, gy = goal\n",
    "                        prev_prev_dist = abs(agent._prev_prev_state[0] - gx) + abs(agent._prev_prev_state[1] - gy)\n",
    "                        new_dist = abs(agent._pos[0] - gx) + abs(agent._pos[1] - gy)\n",
    "                        if new_dist >= prev_prev_dist:\n",
    "                            rewards[i] -= 0.05\n",
    "    \n",
    "            goal = self._get_current_goal(i)\n",
    "            if goal is not None:\n",
    "                gx, gy = goal\n",
    "                current_dist = abs(agent._pos[0] - gx) + abs(agent._pos[1] - gy)\n",
    "            else:\n",
    "                current_dist = 0\n",
    "    \n",
    "            agent._prev_goal_dists.append(current_dist)\n",
    "            if len(agent._prev_goal_dists) > 10:\n",
    "                agent._prev_goal_dists.pop(0)\n",
    "    \n",
    "            if len(agent._prev_goal_dists) >= 5 and len(set(agent._prev_goal_dists[-5:])) == 1:\n",
    "                rewards[i] -= 0.1\n",
    "    \n",
    "            if blocked_flags[i] or (goal is not None and np.array_equal(agent._pos, agent._prev_state)):\n",
    "                rewards[i] -= 0.1\n",
    "    \n",
    "        # -------------------------\n",
    "        # termination logic\n",
    "        # -------------------------\n",
    "        self._move_length -= 1\n",
    "    \n",
    "        all_delivered = (len(self._packages) == 0) or all(getattr(p, \"_delivered\", False) for p in self._packages)\n",
    "        terminated = all_delivered and all(a._carrying is None for a in self._agents)\n",
    "        truncated = self._move_length <= 0\n",
    "    \n",
    "        total_reward = sum(rewards)\n",
    "        return self._obs(), total_reward, terminated, truncated, {}\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    def render(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                sys.exit()\n",
    "\n",
    "        for i in range(15):\n",
    "            for j in range(28):\n",
    "                tile = self._map[i][j]\n",
    "\n",
    "                if tile in {\"#\", \"%\"}:\n",
    "                    color = self._colors[\"wall\"]\n",
    "                elif tile == \"@\":\n",
    "                    color = self._colors[\"shelf\"]\n",
    "                elif tile == \"O\":\n",
    "                    color = self._colors[\"offload\"]\n",
    "                else:\n",
    "                    color = self._colors[\"empty\"]\n",
    "\n",
    "                pygame.draw.rect(\n",
    "                    self._screen, color,\n",
    "                    (j * self._tile_size, i * self._tile_size,\n",
    "                     self._tile_size, self._tile_size)\n",
    "                )\n",
    "\n",
    "        for p in self._packages:\n",
    "            if getattr(p, \"_picked\", False):\n",
    "                continue  \n",
    "            if isinstance(p, ExpressPackage):\n",
    "                pkg_color = self._colors[\"express_package\"]\n",
    "            elif isinstance(p, HeavyPackage):\n",
    "                pkg_color = self._colors[\"heavy_package\"]\n",
    "            else:\n",
    "                pkg_color = self._colors[\"normal_package\"]\n",
    "            x, y = p._pos\n",
    "            pygame.draw.rect(\n",
    "                self._screen, pkg_color,\n",
    "                (y * self._tile_size, x * self._tile_size,\n",
    "                 self._tile_size, self._tile_size)\n",
    "            )\n",
    "\n",
    "\n",
    "        for i in range(self._agent_num):\n",
    "            ax, ay = self._agents[i]._pos\n",
    "            pygame.draw.rect(\n",
    "                self._screen, self._colors[\"agent\"],\n",
    "                (ay * self._tile_size, ax * self._tile_size,\n",
    "                 self._tile_size, self._tile_size)\n",
    "            )\n",
    "\n",
    "        pygame.display.flip()\n",
    "        pygame.time.wait(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing the environments with random actions\n",
    "env = WareHouseEnv()\n",
    "env.init_pygame()\n",
    "env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dadae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e13183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##this is for testing the env with no models and random action\n",
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        # Clear console (optional, makes the render look like animation)\n",
    "        os.system(\"cls\" if os.name == \"nt\" else \"clear\")\n",
    "\n",
    "        env.render()       # <-- render current state\n",
    "\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "\n",
    "        time.sleep(0.05)   # slow down for visibility (adjust as needed)\n",
    "\n",
    "    print(f\"Episode {episode} Score {score}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit() #remember to run pygame.quit() after every run, or the render() will get bugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b80b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training, do not run here, load the model instead, the code is here for record keeping sake\n",
    "log_path = os.path.join(\"Training\",\"Logs\")\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
    "model.learn(total_timesteps=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f3e2fc-e2b3-4ac2-b1e1-4bd61d80de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load model \n",
    "model = PPO.load(r\"C:\\Users\\Brian\\Downloads\\warehouse\\Q_learn\\Training\\Saved Models\\WareHouse_Model_multi_ver4_PPO.zip\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784d404-1b71-4e1b-948d-1f3d433fd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model with env\n",
    "env = WareHouseEnv()\n",
    "env.init_pygame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1eb89-e879-44a3-87da-876e17fa8985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##test out model performance\n",
    "\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        # Clear console (optional, makes the render look like animation)\n",
    "        os.system(\"cls\" if os.name == \"nt\" else \"clear\")\n",
    "\n",
    "        env.render()       # <-- render current state\n",
    "\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "\n",
    "        time.sleep(0.05)   # slow down for visibility (adjust as needed)\n",
    "\n",
    "    print(f\"Episode {episode} Score {score}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17b9ce-55f1-4c88-8d03-8ffe86a78074",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (gym)",
   "language": "python",
   "name": "breakout"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
